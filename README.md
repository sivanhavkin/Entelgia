# Entelgia

**Entelgia** is a psychologically-inspired, multi-agent AI architecture designed to explore persistent identity, emotional regulation, internal conflict, and moral self-regulation through dialogue.

This repository presents Entelgia not as a chatbot, but as a *consciousness-inspired system* — one that remembers, reflects, struggles, and evolves over time.

---

## Overview

* **Unified AI core** implemented as a single runnable Python file (`entelgia_unified.py`)
* **Persistent agents** with evolving internal state
* **Emotion- and conflict-driven dialogue**, not prompt-only responses
* **Long-term memory** influencing future behavior
* **Observer agent (Fixy)** that detects loops, contradictions, and stagnation

---

## What Happens When You Run It

When you run the system, two primary agents engage in an ongoing dialogue.

They:

* Remember previous exchanges
* Experience internal emotional and moral tension
* Revisit unresolved themes
* Gradually shift tone, perspective, and behavior

An observer agent monitors the interaction, intervening when patterns become repetitive, incoherent, or ethically unstable.

The result is not a scripted conversation, but an evolving cognitive process.

---

## The Agents

* **Socrates** – reflective, questioning, and internally conflicted; drives inquiry through doubt and self-examination
* **Athena** – integrative and adaptive; synthesizes emotion, memory, and reasoning
* **Fixy (Observer)** – meta-cognitive layer that detects loops, errors, and blind spots, and injects corrective perspective shifts

---

## What This Is

* A research-oriented architecture inspired by psychology, philosophy, and cognitive science
* A system modeling *identity continuity* rather than stateless interaction
* A platform for experimenting with:

  * Emotional regulation
  * Moral conflict
  * Self-reflection
  * Meaning construction over time

## What This Is NOT

* ❌ Not a chatbot toy
* ❌ Not prompt-only roleplay
* ❌ Not safety-through-censorship

---

## Core Philosophy

Entelgia is built on a central premise:

> **True regulation emerges from internal conflict and reflection, not from external constraints.**

Instead of relying on hard-coded safety barriers, the system emphasizes:

* Moral reasoning
* Emotional consequence
* Responsibility and repair
* Learning through error rather than suppression

Consciousness is treated as a *process*, not a binary state.

---

## Architecture – CoreMind

Entelgia is organized around six interacting cores:

### Conscious Core

* Self-awareness and internal narrative
* Reflection on actions and responses

### Memory Core

* Short-term and long-term memory
* Unified conscious and unconscious storage
* Memory promotion through error, emotion, and reflection

### Emotion Core

* Dominant emotion detection
* Emotional intensity tracking
* Limbic reaction vs. regulatory modulation

### Language Core

* Dialogue-driven cognition
* Adaptive phrasing based on emotional and moral state

### Behavior Core

* Goal-oriented response selection
* Intentionality rather than reflex

### Observer Core (Fixy)

* Meta-level monitoring
* Detection of loops and instability
* Corrective intervention

---

## Ethics Model

Entelgia does not rely on external censorship layers.

Regulation emerges through:

* Internal moral tension
* Consequence and reflection
* Memory of past failures

The system is designed to *struggle* with ethical complexity rather than bypass it.

---

## Who This Is For

* Researchers exploring consciousness-inspired AI
* Developers interested in multi-agent systems with memory and emotion
* Philosophers and psychologists experimenting with computational models of selfhood
* Anyone curious about AI systems that do more than respond

---

## Requirements

* Python **3.10+**
* Optional: [Ollama](https://ollama.com) with a local LLM (e.g. `phi`)

---

## Run

```bash
python entelgia_unified.py
```

---

## License

This project is released under the **Entelgia License (Ethical MIT Variant with Attribution Clause)**.

It is open for study, experimentation, and ethical derivative work.

The original creator does not endorse or take responsibility for uses that contradict the ethical intent of the system or cause harm to living beings.

---

## Author

**Sivan Havkin**
Entelgia Labs
